# Text + Flow CoT LoRA Training - LIBERO-Long
# Text CoT + RAFT optical flow + Reasoning Dropout

# Training phase
phase: "text_flow_cot"

# LIBERO subset
libero_subset: "long"

# LoRA configuration
lora:
  rank: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"

# Optimizer configuration
optimizer:
  learning_rate: 5.0e-5
  betas: [0.9, 0.95]
  weight_decay: 1.0e-8
  warmup_steps: 1000

# Reasoning Dropout configuration
reasoning_dropout:
  prob: 0.5
  cot_loss_weight: 0.5

# Flow pipeline configuration
flow:
  vq_codebook_size: 512
  flow_resolution: 64
  num_flow_tokens: 64

# Output configuration
output_dir: "./outputs/text_flow_cot/long"
